<!-- Coggle 30 Days of ML（23年1月） -->
<!-- 30天入门数据竞赛 -->
<!-- 2023-01-04 -->
<!-- <a target="_blank" href="https://www.zhihu.com/people/ashui233/">阿水</a>, <a target="_blank" href="https://www.zhihu.com/people/wang-he-13-93">鱼遇雨欲语与余</a>-->
<!-- <a href="https://coggle.club/blog/30days-of-ml-202212">学习资料</a>##<a href="https://shimo.im/forms/baG3JezwfX0itOA8/fill">打卡链接</a>-->

## Part1 内容介绍

本月竞赛学习将以文本匹配问题展开，文本匹配拥有广泛的应用场景，可以用于去除重复问题和文本相似度中。在本次学习中我们将学习：

- 如何计算文本之间的统计距离
- 如何训练词向量 & 无监督句子编码
- BERT模型搭建和训练

上述步骤都是一个NLP算法工程师必备的基础，在本月我们将逐步从基础出发，逐步解决文本匹配问题。


## Part2 活动安排


* 免费学习活动，不会收取任何费用。
* **请各位同学添加下面微信，并回复【竞赛学习】，即可参与。**

![](https://cdn.coggle.club/coggle666_qrcode.png)


## Part3 积分说明和奖励

为了激励各位同学完成的学习任务，将学习任务根据难度进行划分，并根据是否完成进行评分难度高中低的任务分别分数为3、2和1。在完成学习后（本次活动，截止2月1），将按照积分顺序进行评选 Top3 的学习者。

打卡链接(可以重复提交)：[https://shimo.im/forms/baG3JezwfX0itOA8/fill](https://shimo.im/forms/baG3JezwfX0itOA8/fill)

**打卡可以写在一个地址，每次有新完成的可以重复提交打卡！**

| 昵称                       | 得分  |
| :----------------------------- | :---- |
| chal1ce |8 |
| 徐乜乜  | 3 |
| 张不懂D |3 |
| HowieHsu0126 | 2 |
| 王鹏 | 2 |
| 江东 | 2 |
| 逐鹿-长风 | 1 |
| 静俐 | 1 |
| 迪 | 1 |
| ruler同学 | 1 |
| 逐鹿-长风 | 1 |


Top1的学习者将获得以下**奖励**：
* Coggle 竞赛专访机会
* 《机器学习算法竞赛实战》

Top2-3的学习者将获得以下**奖励**：
* Coggle 周边福利
* Coggle 竞赛专访机会

历史活动打卡链接，可以参考如下格式：
- [https://blog.csdn.net/weixin_42551154/article/details/125474519](https://blog.csdn.net/weixin_42551154/article/details/125474519)
- [https://blog.csdn.net/weixin_42551154/article/details/125481695](https://blog.csdn.net/weixin_42551154/article/details/125481695)


## Part4 文本相似度匹配

### 背景介绍

文本语义匹配是自然语言处理中一个重要的基础问题，NLP 领域的很多任务都可以抽象为文本匹配任务。例如，信息检索可以归结为查询项和文档的匹配，问答系统可以归结为问题和候选答案的匹配，对话系统可以归结为对话和回复的匹配。语义匹配在搜索优化、推荐系统、快速检索排序、智能客服上都有广泛的应用。如何提升文本匹配的准确度，是自然语言处理领域的一个重要挑战。

- 信息检索：在信息检索领域的很多应用中，都需要根据原文本来检索与其相似的其他文本，使用场景非常普遍。
- 新闻推荐：通过用户刚刚浏览过的新闻标题，自动检索出其他的相似新闻，个性化地为用户做推荐，从而增强用户粘性，提升产品体验。
- 智能客服：用户输入一个问题后，自动为用户检索出相似的问题和答案，节约人工客服的成本，提高效率。

让我们来看一个简单的例子，比较各候选句子哪句和原句语义更相近：

- 原句：“车头如何放置车牌”
- 比较句1：“前牌照怎么装”
- 比较句2：“如何办理北京车牌”
- 比较句3：“后牌照怎么装”

比较结果：
- 比较句1与原句，虽然句式和语序等存在较大差异，但是所表述的含义几乎相同
- 比较句2与原句，虽然存在“如何” 、“车牌”等共现词，但是所表述的含义完全不同
- 比较句3与原句，二者讨论的都是如何放置车牌的问题，只不过一个是前牌照，另一个是后牌照。二者间存在一定的语义相关性
- 所以语义相关性，句1大于句3，句3大于句2，这就是语义匹配。

### 数据说明

[LCQMC数据集](http://icrc.hitsz.edu.cn/Article/show/171.html)比释义语料库更通用，因为它侧重于意图匹配而不是释义。LCQMC数据集包含 260,068 个带有人工标注的问题对。

- 包含 238,766 个问题对的训练集
- 包含 8,802 个问题对的开发集
- 包含 12,500 个问题对的测试集


### 评估方式

使用准确率Accuracy来评估，即：

$$准确率(Accuracy) = 预测正确的条目数 / 预测总条目数$$

也可以使用文本相似度与标签的皮尔逊系数进行评估，不匹配的文本相似度应该更低。

### 学习打卡

| 任务名称                       | 难度  |
| :----------------------------- | :---- |
| 任务1：数据集读取        | 低、1 |
| 任务2：文本数据分析        | 低、1 |
| 任务3：文本相似度（统计特征）        | 中、2 |
| 任务4：文本相似度（词向量与句子编码）        | 高、3 |
| 任务5：文本匹配模型（LSTM孪生网络）        | 中、2 |
| 任务6：文本匹配模型（Sentence-BERT模型）        | 高、3 |
| 任务7：文本匹配模型（SimCSE模型）        | 高、3 |

- 任务1：数据集读取

自然语言处理(Natural Language Processing, NLP)是计算机科学、人工智能和语言学的交叉领域，其目标是使计算机能够理解、生成和处理人类语言。常见的 NLP 技术包括语音识别、文本分析、机器翻译等。这些技术都是基于人工智能和机器学习的算法来实现的。

文本匹配是自然语言处理中的一种常见任务。它可以用来判断两个文本之间的相似度或相关性。常见的文本匹配任务包括：文本相似性匹配、问答匹配、查询-文档匹配等。这些任务的具体实现可以使用机器学习技术，例如使用神经网络模型进行文本嵌入，然后使用余弦相似度或其他相似度度量来计算文本之间的相似度。

LCQMC（Large-scale Chinese Question Matching Corpus）是一个大规模的中文文本匹配数据集。它包含超过 400,000 个标记为重复或非重复的问题对。该数据集由中国科学院自动化研究所（CASIA）深度学习技术与应用国家工程实验室（NEL-DLT）创建。

LCQMC 数据集中的问题涵盖广泛的主题，并以口语化的中文编写，使其成为文本匹配模型具有挑战性的数据集。该数据集通常用于训练和评估各种中文文本匹配模型的性能，例如基于神经网络的模型。它还用于中文自然语言处理的研究，例如文本匹配、文本分类和其他 NLP 任务。该数据集为研究人员提供了一个基准，用于评估其模型的性能并将其与最先进的方法进行比较。

```
import pandas as pd

def load_lcqmc():
    '''LCQMC文本匹配数据集
    '''
    train = pd.read_csv('https://mirror.coggle.club/dataset/LCQMC.train.data.zip', 
            sep='\t', names=['query1', 'query2', 'label'])

    valid = pd.read_csv('https://mirror.coggle.club/dataset/LCQMC.valid.data.zip', 
            sep='\t', names=['query1', 'query2', 'label'])

    test = pd.read_csv('https://mirror.coggle.club/dataset/LCQMC.test.data.zip', 
            sep='\t', names=['query1', 'query2', 'label'])

    return train, valid, test
```

- 任务2：文本数据分析
    - 步骤1：分析赛题文本长度，相似文本对与不相似文本对的文本长度是否存在差异？
    - 步骤2：分析赛题单词和字符个数，在所有文本中包含多少个单词（用jieba进行分析）和字符？

在LCQMC数据集中数据采用三列进行存储，其中label为是否含义相同的标签。在任务2中我们希望各位同学，能对中文文本进出初步的分析，找到相似文本对和不相似文本对的差异。

|      | query1                           | query2                         | label |
| ---- | -------------------------------- | ------------------------------ | ----- |
| 0    | 喜欢打篮球的男生喜欢什么样的女生 | 爱打篮球的男生喜欢什么样的女生 | 1     |
| 1    | 我手机丢了，我想换个手机         | 我想买个新手机，求推荐         | 1     |
| 2    | 大家觉得她好看吗                 | 大家觉得跑男好看吗？           | 0     |

jieba是一个中文分词库，用于将中文句子分解为词组。它使用了基于前缀词典的最大匹配算法，并支持用户自定义词典。要使用Jieba库，首先需要安装它。使用 pip 可以轻松安装：

```
pip install jieba
```

安装完成后，可以使用下面的代码对句子进行分词：

```
import jieba
sentence = "我在学习使用jieba分词"
seg_list = jieba.cut(sentence)
print(" ".join(seg_list))
```

输出结果是：我 在 学习 使用 jieba 分词。还可以使用jieba.lcut() or jieba.lcut_for_search() 获取词组列表。


- 任务3：文本相似度（统计特征） 
    - 步骤1：对query1和query2计算文本统计特征
        - query1和query2文本长度
        - query1和query2文本单词个数
        - query1和query2文本单词差异
        - query1和query2文本最长公用字符串长度
        - query1和query2文本的TFIDF编码相似度
    - 步骤2：根据相似度标签，上述哪一个特征最有区分性？
- 任务4：文本相似度（词向量与句子编码） 
    - 步骤1：使用jieba分词，然后使用word2vec训练词向量
    - 步骤2：计算单词的TFIDF和BM25权重
    - 步骤3：尝试如下无监督句子编码过程
        - Mean-Pooling
        - Max-Pooling
        - IDF-Pooling
        - BM25-Pooling
        - SIF-Pooling
    - 步骤4：根据相似度标签，上述哪一个特征最有区分性？
- 任务5：文本匹配模型（LSTM孪生网络）
    - 步骤1：定义孪生网络（嵌入层、LSTM层、全连接层）
    - 步骤2：使用比赛数据训练孪生网络
    - 步骤3：对测试数据进行预测
- 任务6：文本匹配模型（Sentence-BERT模型）
    - 步骤1：定义SBERT网络
    - 步骤2：使用比赛数据训练孪生网络
    - 步骤3：对测试数据进行预测
- 任务7：文本匹配模型（SimCSE模型）
    - 步骤1：定义SimCSE网络和损失函数
    - 步骤2：使用比赛数据先进行无监督训练，然后进行有监督训练
    - 步骤3：对测试数据进行预测


### 学习资料

- [赛题及baseline解读视频](https://tianchi.aliyun.com/course/1160)
- [baseline：孪生网络思路](https://tianchi.aliyun.com/notebook/409641)
- [baseline：LSTM思路](https://tianchi.aliyun.com/notebook/409589)
- [baseline：Attention思路](https://tianchi.aliyun.com/notebook/408081)
- [baseline：BERT思路](https://tianchi.aliyun.com/notebook/409593)