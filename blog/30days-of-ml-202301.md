<!-- Coggle 30 Days of ML（23年1月） -->
<!-- 30天入门数据竞赛 -->
<!-- 2023-01-04 -->
<!-- <a target="_blank" href="https://www.zhihu.com/people/ashui233/">阿水</a>, <a target="_blank" href="https://www.zhihu.com/people/wang-he-13-93">鱼遇雨欲语与余</a>-->
<!-- <a href="https://coggle.club/blog/30days-of-ml-202212">学习资料</a>##<a href="https://shimo.im/forms/baG3JezwfX0itOA8/fill">打卡链接</a>-->

## Part1 内容介绍

本月竞赛学习将以文本匹配问题展开，文本匹配拥有广泛的应用场景，可以用于去除重复问题和文本相似度中。在本次学习中我们将学习：

- 如何计算文本之间的统计距离
- 如何训练词向量 & 无监督句子编码
- BERT模型搭建和训练

上述步骤都是一个NLP算法工程师必备的基础，在本月我们将逐步从基础出发，逐步解决文本匹配问题。


## Part2 活动安排


* 免费学习活动，不会收取任何费用。
* **请各位同学添加下面微信，并回复【竞赛学习】，即可参与。**

![](https://cdn.coggle.club/coggle666_qrcode.png)


## Part3 积分说明和奖励

为了激励各位同学完成的学习任务，将学习任务根据难度进行划分，并根据是否完成进行评分难度高中低的任务分别分数为3、2和1。在完成学习后（本次活动，截止2月1），将按照积分顺序进行评选 Top3 的学习者。

打卡链接(可以重复提交)：[https://shimo.im/forms/baG3JezwfX0itOA8/fill](https://shimo.im/forms/baG3JezwfX0itOA8/fill)

**打卡可以写在一个地址，每次有新完成的可以重复提交打卡！**

| 昵称                       | 得分  |
| :----------------------------- | :---- |
| chal1ce |8 |
| 徐乜乜  | 3 |
| 张不懂D |3 |
| HowieHsu0126 | 2 |
| 王鹏 | 2 |
| 江东 | 2 |
| 逐鹿-长风 | 1 |
| 静俐 | 1 |
| 迪 | 1 |
| ruler同学 | 1 |
| 逐鹿-长风 | 1 |


Top1的学习者将获得以下**奖励**：
* Coggle 竞赛专访机会
* 《机器学习算法竞赛实战》

Top2-3的学习者将获得以下**奖励**：
* Coggle 周边福利
* Coggle 竞赛专访机会

历史活动打卡链接，可以参考如下格式：
- [https://blog.csdn.net/weixin_42551154/article/details/125474519](https://blog.csdn.net/weixin_42551154/article/details/125474519)
- [https://blog.csdn.net/weixin_42551154/article/details/125481695](https://blog.csdn.net/weixin_42551154/article/details/125481695)


## Part4 文本相似度匹配

### 背景介绍

文本语义匹配是自然语言处理中一个重要的基础问题，NLP 领域的很多任务都可以抽象为文本匹配任务。例如，信息检索可以归结为查询项和文档的匹配，问答系统可以归结为问题和候选答案的匹配，对话系统可以归结为对话和回复的匹配。语义匹配在搜索优化、推荐系统、快速检索排序、智能客服上都有广泛的应用。如何提升文本匹配的准确度，是自然语言处理领域的一个重要挑战。

- 信息检索：在信息检索领域的很多应用中，都需要根据原文本来检索与其相似的其他文本，使用场景非常普遍。
- 新闻推荐：通过用户刚刚浏览过的新闻标题，自动检索出其他的相似新闻，个性化地为用户做推荐，从而增强用户粘性，提升产品体验。
- 智能客服：用户输入一个问题后，自动为用户检索出相似的问题和答案，节约人工客服的成本，提高效率。

让我们来看一个简单的例子，比较各候选句子哪句和原句语义更相近：

- 原句：“车头如何放置车牌”
- 比较句1：“前牌照怎么装”
- 比较句2：“如何办理北京车牌”
- 比较句3：“后牌照怎么装”

比较结果：
- 比较句1与原句，虽然句式和语序等存在较大差异，但是所表述的含义几乎相同
- 比较句2与原句，虽然存在“如何” 、“车牌”等共现词，但是所表述的含义完全不同
- 比较句3与原句，二者讨论的都是如何放置车牌的问题，只不过一个是前牌照，另一个是后牌照。二者间存在一定的语义相关性
- 所以语义相关性，句1大于句3，句3大于句2，这就是语义匹配。

### 数据说明

[LCQMC数据集](http://icrc.hitsz.edu.cn/Article/show/171.html)比释义语料库更通用，因为它侧重于意图匹配而不是释义。LCQMC数据集包含 260,068 个带有人工标注的问题对。

- 包含 238,766 个问题对的训练集
- 包含 8,802 个问题对的开发集
- 包含 12,500 个问题对的测试集


### 评估方式

使用准确率Accuracy来评估，即：

$$准确率(Accuracy) = 预测正确的条目数 / 预测总条目数$$

也可以使用文本相似度与标签的皮尔逊系数进行评估，不匹配的文本相似度应该更低。

### 学习打卡

| 任务名称                       | 难度  |
| :----------------------------- | :---- |
| 任务1：数据集读取        | 低、1 |
| 任务2：文本数据分析        | 低、1 |
| 任务3：文本相似度（统计特征）        | 中、2 |
| 任务4：文本相似度（词向量与句子编码）        | 高、3 |
| 任务5：文本匹配模型（LSTM孪生网络）        | 中、2 |
| 任务6：文本匹配模型（Sentence-BERT模型）        | 高、3 |
| 任务7：文本匹配模型（SimCSE模型）        | 高、3 |

- 任务1：数据集读取
```
import pandas as pd

def load_lcqmc():
    '''LCQMC文本匹配数据集
    '''
    train = pd.read_csv('https://mirror.coggle.club/dataset/LCQMC.test.data.zip', 
            sep='\t', names=['query1', 'query2', 'label'])

    valid = pd.read_csv('https://mirror.coggle.club/dataset/LCQMC.test.data.zip', 
            sep='\t', names=['query1', 'query2', 'label'])

    test = pd.read_csv('https://mirror.coggle.club/dataset/LCQMC.test.data.zip', 
            sep='\t', names=['query1', 'query2', 'label'])

    return train, valid, test
```

- 任务2：文本数据分析
    - 步骤1：分析赛题文本长度，相似文本对与不相似文本对的文本长度是否存在差异？
    - 步骤2：分析赛题单词和字符个数，在所有文本中包含多少个单词（用jieba进行分析）和字符？
- 任务3：文本相似度（统计特征） 
    - 步骤1：对query1和query2计算文本统计特征
        - query1和query2文本长度
        - query1和query2文本单词个数
        - query1和query2文本单词差异
        - query1和query2文本最长公用字符串长度
        - query1和query2文本的TFIDF编码相似度
    - 步骤2：根据相似度标签，上述哪一个特征最有区分性？
- 任务4：文本相似度（词向量与句子编码） 
    - 步骤1：使用jieba分词，然后使用word2vec训练词向量
    - 步骤2：计算单词的TFIDF和BM25权重
    - 步骤3：尝试如下无监督句子编码过程
        - Mean-Pooling
        - Max-Pooling
        - IDF-Pooling
        - BM25-Pooling
        - SIF-Pooling
    - 步骤4：根据相似度标签，上述哪一个特征最有区分性？
- 任务5：文本匹配模型（LSTM孪生网络）
    - 步骤1：定义孪生网络（嵌入层、LSTM层、全连接层）
    - 步骤2：使用比赛数据训练孪生网络
    - 步骤3：对测试数据进行预测
- 任务6：文本匹配模型（Sentence-BERT模型）
    - 步骤1：定义SBERT网络
    - 步骤2：使用比赛数据训练孪生网络
    - 步骤3：对测试数据进行预测
- 任务7：文本匹配模型（SimCSE模型）
    - 步骤1：定义SimCSE网络和损失函数
    - 步骤2：使用比赛数据先进行无监督训练，然后进行有监督训练
    - 步骤3：对测试数据进行预测


### 学习资料

- [赛题及baseline解读视频](https://tianchi.aliyun.com/course/1160)
- [baseline：孪生网络思路](https://tianchi.aliyun.com/notebook/409641)
- [baseline：LSTM思路](https://tianchi.aliyun.com/notebook/409589)
- [baseline：Attention思路](https://tianchi.aliyun.com/notebook/408081)
- [baseline：BERT思路](https://tianchi.aliyun.com/notebook/409593)