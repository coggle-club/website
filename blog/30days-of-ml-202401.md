<!-- Coggle 30 Days of ML（24年1/2月） -->
<!-- 30天入门数据竞赛 -->
<!-- 2023-01-18 -->
<!-- <a target="_blank" href="https://www.zhihu.com/people/ashui233/">阿水</a>, <a target="_blank" href="https://www.zhihu.com/people/wang-he-13-93">鱼遇雨欲语与余</a>-->
<!-- <a href="https://coggle.club/blog/30days-of-ml-202401">学习资料</a>##<a href="https://shimo.im/forms/sUvnh7XGiHHRV3MI/fill">打卡链接</a>-->

## Part1 内容介绍

在自然语言处理领域，大型语言模型（LLM）如GPT-3、BERT等已经取得了显著的进展，它们能够生成连贯、自然的文本，回答问题，并执行其他复杂的语言任务。然而，这些模型存在一些固有的局限性，如“模型幻觉问题”、“时效性问题”和“数据安全问题”。为了克服这些限制，检索增强生成（RAG）技术应运而生。

RAG技术结合了大型语言模型的强大生成能力和检索系统的精确性。它允许模型在生成文本时，从外部知识库中检索相关信息，从而提高生成内容的准确性、相关性和时效性。这种方法不仅增强了模型的回答能力，还减少了生成错误信息的风险。


本月的学习内容主要围绕检索增强生成（RAG）技术展开：
- RAG技术背景与动机
- RAG技术基本原理和技术流程
- 知识库构建与管理、检索模块技术
- ChatGPT/ChatGLM的API使用

## Part2 活动安排


* 免费学习活动，不会收取任何费用。
* **请各位同学添加下面微信，并回复【竞赛学习】，即可参与。**

![](https://cdn.coggle.club/coggle101_qrcode.jpeg)


## Part3 积分说明和奖励

为了激励各位同学完成的学习任务，在完成学习后（本次活动，截止2月29），将按照积分顺序进行评选 Top3 的学习者。如果打卡积分相同，则按照prompt质量和文本长度进行排序。

打卡地址：[https://shimo.im/forms/sUvnh7XGiHHRV3MI/fill](https://shimo.im/forms/sUvnh7XGiHHRV3MI/fill)


### 打卡积分奖励


Top1的学习者将获得以下奖励：

- 50元现金红包
- Coggle 竞赛专访机会

Top2-3的学习者将获得以下奖励：
- 20元红包
- Coggle 竞赛专访机会


历史活动打卡链接，可以参考如下格式：
- [https://blog.csdn.net/weixin_42551154/article/details/125474519](https://blog.csdn.net/weixin_42551154/article/details/125474519)
- [https://blog.csdn.net/weixin_42551154/article/details/125481695](https://blog.csdn.net/weixin_42551154/article/details/125481695)


## Part4 动手学RAG

### 背景介绍

本次活动参赛选手以大模型为中心制作一个问答系统，回答用户的汽车相关问题。参赛选手需要根据问题，在文档中定位相关信息的位置，并根据文档内容通过大模型生成相应的答案。涉及的问题主要围绕汽车使用、维修、保养等方面。

```
问题1：怎么打开危险警告灯？
答案1：危险警告灯开关在方向盘下方，按下开关即可打开危险警告灯。

问题2：车辆如何保养？
答案2：为了保持车辆处于最佳状态，建议您定期关注车辆状态，包括定期保养、洗车、内部清洁、外部清洁、轮胎的保养、低压蓄电池的保养等。

问题3：靠背太热怎么办？
答案3：您好，如果您的座椅靠背太热，可以尝试关闭座椅加热功能。在多媒体显示屏上依次点击空调开启按键→座椅→加热，在该界面下可以关闭座椅加热。
```

### 打卡任务
| 任务名称                                        | 所需技能             |
| ----------------------------------------------- | -------------------- |
| 任务1：初始RAG              | 无               |
| 任务2：ChatGPT/GLM API使用             | Python               |
| 任务3：读取汽车问答数据集              | Python               |
| 任务4：文本索引与答案检索              | TFIDF、BM25               |
| 任务5：文本嵌入与向量检索              | Embedding、transformer               |
| 任务6：文本多路召回与重排序              | ReRank               |
| 任务8：文本问答Promopt优化              | Python               |
| 任务9：问答意图识别（进阶方向）              | BERT/TFIDF               |
| 任务10：问答关键词提取（进阶方向）              | TextRank               |
| 任务11：扩展词与扩展查询（进阶方向）              | Word2Vec/BART               |
| 任务12：本地微调ChatGLM（进阶方向）              | ChatGLM               |

#### 任务1：初始RAG

- 任务说明：了解到现有大模型的缺陷和RAG的优点和流程
- 任务要求：
    - 了解大模型现有的缺点
    - 理解RAG的流程和实现步骤
    - 清楚RAG的需要的技术
- 打卡要求：阅读LangChain与RAG的[文章](https://juejin.cn/post/7310569308916334604)和LangChain的[官方文档](https://python.langchain.com/docs/expression_language/cookbook/retrieval)，列举LangChain能实现的功能。

> 大模型的局限性

大型语言模型在自然语言处理领域展示了显著的能力，但它们也存在一系列固有的缺点。首先，虽然这些模型在掌握大量信息方面非常有效，但它们的结构和参数数量使得对其进行修改、微调或重新训练变得异常困难，且相关成本相当可观。

其次，大型语言模型的应用往往依赖于构建适当的提示（prompt）来引导模型生成所需的文本。这种方法通过将信息嵌入到提示中，从而引导模型按照特定的方向生成文本。然而，这种基于提示的方法可能使模型过于依赖先前见过的模式，而无法真正理解问题的本质。

| **大模型现存问题** | 大型语言模型的局限性 |
|----------|------------------------|
| 问题1.1  | 模型幻觉问题：生成内容可能不准确或不一致 |
| 问题1.2  | 时效性问题：生成的内容不具有当前时效性 |
| 问题1.3  | 数据安全问题：可能存在敏感信息泄露风险 |

在自然语言处理领域，幻觉（Hallucination）被定义为生成的内容与提供的源内容无关或不忠实，具体而言，是一种虚假的感知，但在表面上却似乎是真实的。在一般语境中，幻觉是一个心理学术语，指的是一种特定类型的感知。在自然语言处理或大型语言模型的语境下，这种感知即为一种虚假的、不符合实际的信息。

造成幻觉的原因主要可以归结为数据驱动原因、表示和解码的不完善以及参数知识偏见。首先，数据对不齐或不匹配可能导致幻觉，因为模型在训练中未能准确地理解源内容与参考内容之间的关系。

> 知识库问答（Knowledge Base Question Answering，KBQA）

知识库问答（Knowledge Base Question Answering，简称KBQA）是一种早期的对话系统方法，旨在利用结构化的知识库进行自然语言问题的回答。这种方法基于一个存储在图数据库中的知识库，通常以三元组的形式表示为<主题，关系，对象>，其中每个三元组都附带相关的属性信息。

知识库问答早期是对话系统中的有效方法，其基于知识图谱的结构为系统提供了丰富的语义信息，使得系统能够更深入地理解用户提出的问题，并以结构化的形式回答这些问题。随着技术的不断发展，KBQA方法也在不断演进，为对话系统的进一步提升奠定了基础。

在KBQA中，有两种主流方法用于处理自然语言问题：
- 主题识别与实体链接：该方法从识别问题中的主题开始，将其链接到知识库中的实体（称为主题实体）。通过主题实体，系统能够在知识库中查找相关的信息并回答问题。
- 多跳查询：基于图数据库的优势，KBQA能够进行多跳查询，即通过多个关系跨越多个实体来获取更深层次的信息。这种灵活性使得系统能够更全面地理解和回答用户的复杂问题。

> RAG介绍

检索增强生成（RAG）技术在弥补大型语言模型（LLM）的局限性方面取得了显著进展，尤其是在解决幻觉问题和提升实效性方面。在之前提到的LLM存在的问题中，特别是幻觉问题和时效性问题，RAG技术通过引入外部知识库的检索机制，成功提升了生成内容的准确性、相关性和时效性。

- RAG技术通过检索外部知识库，避免了幻觉问题的困扰。相较于单纯依赖大型语言模型对海量文本数据的学习，RAG允许模型在生成文本时从事实丰富的外部知识库中检索相关信息。
- RAG技术的时效性优势使其在处理实效性较强的问题时更为可靠。通过与外部知识库的连接，RAG确保了模型可以获取最新的信息，及时适应当前的事件和知识。
- 与传统的知识库问答（KBQA）相比，RAG技术在知识检索方面更加灵活，不仅能够从结构化的知识库中检索信息，还能够应对非结构化的自然语言文本。


| **RAG优点** | 描述 |
|-----------------|-----|
| 优点1.1         | 提高准确性和相关性 |
| 优点1.2         | 改善时效性，使模型适应当前事件和知识 |
| 优点1.3         | 降低生成错误风险，依赖检索系统提供的准确信息 |

**RAG被构建为一个应用于大型语言模型的框架，其目标是通过结合大模型的生成能力和外部知识库的检索机制，提升自然语言处理任务的效果。** RAG并非旨在取代已有的知识库问答（KBQA）系统，而是作为一种补充，利用检索机制强调实时性和准确性，从而弥补大型语言模型固有的局限性。

RAG框架的最终输出被设计为一种协同工作模式，将检索到的知识融合到大型语言模型的生成过程中。在应对任务特定问题时，RAG会生成一段标准化的句子，引导大模型进行回答。下面是RAG输出到大型语言模型的典型模板：

```
你是一个{task}方面的专家，请结合给定的资料，并回答最终的问题。请如实回答，如果问题在资料中找不到答案，请回答不知道。

问题：{question}

资料：
- {information1}
- {information2}
- {information3}
```

其中，`{task}`代表任务的领域或主题，`{question}`是最终要回答的问题，而`{information1}`、`{information2}`等则是提供给模型的外部知识库中的具体信息。

> RAG和SFT对比

在更新大型语言模型的知识方面，微调模型和使用RAG这两种方法有着各自的优缺点。微调模型优势在于能够通过有监督学习的方式，通过对任务相关数据的反复迭代调整，使得模型更好地适应特定领域的知识和要求。RAG能够从外部知识库中检索最新、准确的信息，从而提高了答案的质量和时效性。其优势在于可以利用最新的外部信息，从而更好地适应当前事件和知识。

|      | 微调模型                                               | RAG                                                          |
| ---- | ------------------------------------------------------ | ------------------------------------------------------------ |
| 优点 | 针对特定任务调整预训练模型。优点是可针对特定任务优化； | 结合检索系统和生成模型。优点是能利用最新信息，提高答案质量，具有更好的可解释性和适应性： |
| 缺点 | 但缺点是更新成本高，对新信息适应性较差；               | 是可能面临检索质量问题和曾加额外计算资源需求;                |

| 特性       | RAG技术                                    | SFT模型微调                              |
| ---------- | ------------------------------------------ | ---------------------------------------- |
| 知识更新   | 实时更新检索库，适合动态数据，无需频繁重训 | 存储静态信息，更新知识需要重新训练       |
| 外部知识   | 高效利用外部资源，适合各类数据库           | 可对齐外部知识，但对动态数据源不够灵活   |
| 数据处理   | 数据处理需求低                             | 需构建高质量数据集，数据限制可能影响性能 |
| 模型定制化 | 专注于信息检索和整合，定制化程度低         | 可定制行为，风格及领域知识               |
| 可解释性   | 答案可追溯，解释性高                       | 解释性相对低                             |
| 计算资源   | 需要支持检索的计算资源，维护外部数据源     | 需要训练数据集和微调资源                 |
| 延迟要求   | 数据检索可能增加延迟                       | 微调后的模型反应更快                     |
| 减少幻觉   | 基于实际数据，幻觉减少                     | 通过特定域训练可减少幻觉，但仍然有限     |
| 道德和隐私 | 处理外部文本数据时需要考虑隐私和道德问题   | 训练数据的敏感内容可能引发隐私问题       |




> RAG实现流程

如果使用RAG，主要包括信息检索和大型语言模型调用两个关键过程。信息检索通过连接外部知识库，获取与问题相关的信息；而大型语言模型调用则用于将这些信息整合到自然语言生成的过程中，以生成最终的回答。

| **RAG流程** | 描述 |
|-----------------|-----|
| 步骤1：问题理解           |准确把握用户的意图|
| 步骤2：知识检索         | 从知识库中相关的知识检索 |
| 步骤3：答案生成          |将检索结果与问题 |

RAG每个步骤都面临一些挑战，这些挑战使得RAG的实现变得复杂而困难。在问题理解阶段，系统需要准确把握用户的意图。**用户提问往往是短文本，而知识库中的信息可能是长文本。** 将用户提问与知识库中的知识建立有效的关联是一个难点，特别是考虑到用户提问可能模糊，用词不规范，难以直接找到相关的知识。

知识检索是RAG流程中的关键步骤，但也是面临挑战的步骤之一。**用户提问可能以多种方式表达，而知识库的信息来源可能是多样的，包括PDF、PPT、Neo4j等格式。**

**此外用户的意图可能非常灵活，可能是提问，也可能需要进行闲聊** 。在这个阶段，需要确保生成的答案与用户的意图一致，同时保持自然、连贯的文本。此外，大型模型的输出可能存在幻觉问题，即生成的内容可能与问题不相关，增加了生成准确回答的难度。

在论文综述[「Retrieval-Augmented Generation for Large Language Models: A Survey」](https://arxiv.org/pdf/2312.10997.pdf)中，作者将RAG技术按照复杂度继续划分为Naive RAG，Advanced RAG、Modular RAG。

| **技术类型** | **描述** |
|-----------------|---------|
| **Naive RAG**   | Naive RAG是RAG技术的最基本形式，也被称为经典RAG。包括索引、检索、生成三个基本步骤。索引阶段将文档库分割成短的Chunk，并构建向量索引。检索阶段根据问题和Chunks的相似度检索相关文档片段。生成阶段以检索到的上下文为条件，生成问题的回答。 |
| **Advanced RAG** | Advanced RAG在Naive RAG的基础上进行优化和增强。包含额外处理步骤，分别在数据索引、检索前和检索后进行。包括更精细的数据清洗、设计文档结构和添加元数据，以提升文本一致性、准确性和检索效率。在检索前使用问题的重写、路由和扩充等方式对齐问题和文档块之间的语义差异。在检索后通过重排序避免“Lost in the Middle”现象，或通过上下文筛选与压缩缩短窗口长度。 |
| **Modular RAG**  | Modular RAG引入更多具体功能模块，例如查询搜索引擎、融合多个回答等。技术上融合了检索与微调、强化学习等。流程上对RAG模块进行设计和编排，出现多种不同RAG模式。提供更大灵活性，系统可以根据应用需求选择合适的功能模块组合。模块化RAG的引入使得系统更自由、灵活，适应不同场景和需求。 |

在RAG技术流程中，涉及多个关键模块，每个模块承担着特定的任务，协同工作以实现准确的知识检索和生成自然语言回答。

| **技术模块** | **描述** |
|-----------------|---------|
| **意图理解**   | 意图理解模块负责准确把握用户提出的问题，确定用户的意图和主题。处理用户提问的模糊性和不规范性，为后续流程提供清晰的任务目标。 |
| **文档解析** | 文档解析模块用于处理来自不同来源的文档，包括PDF、PPT、Neo4j等格式。该模块负责将文档内容转化为可处理的结构化形式，为知识检索提供合适的输入。 |
| **文档索引**  | 文档索引模块将解析后的文档分割成短的Chunk，并构建向量索引。或通过全文索引进行文本检索，使得系统能够更快速地找到与用户问题相关的文档片段。 |
| **向量嵌入** | 向量嵌入模块负责将文档索引中的内容映射为向量表示，以便后续的相似度计算。这有助于模型更好地理解文档之间的关系，提高知识检索的准确性。 |
| **知识检索**   | 知识检索模块根据用户提问和向量嵌入计算的相似度检索或文本检索打分。这一步骤需要解决问题和文档之间的语义关联，确保检索的准确性。 |
| **重排序** | 重排序模块在知识检索后对文档库进行重排序，以避免“Lost in the Middle”现象，确保最相关的文档片段在前面。 |
| **大模型回答**  | 大模型回答模块利用大型语言模型生成最终的回答。该模块结合检索到的上下文，以生成连贯、准确的文本回答。 |
| **其他功能模块** | 可根据具体应用需求引入其他功能模块，如查询搜索引擎、融合多个回答等。模块化设计使得系统更加灵活，能够根据不同场景选择合适的功能模块组合。 |

### 专业名词介绍

| **专业名词**                    | **描述**                                                                                                                                                                                            |
|-----------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 大型语言模型                   | 在自然语言处理领域展示出强大生成能力的模型，如GPT系列。但其修改、微调或重新训练困难，成本高。                                                                                                                |
| Prompt                        | "Prompt"（提示）是指一种引导大型语言模型（LLM）生成特定文本的方法。或可以理解为输给大模型的输入文本。                                                                                                                |
| 幻觉（Hallucination）          | 在自然语言处理领域被定义为生成的内容与提供的源内容无关或不忠实，一种虚假的感知。                                             |
| 知识库问答（KBQA）              | 早期的对话系统方法，利用结构化的知识库进行自然语言问题的回答。知识库以三元组形式表示<主题，关系，对象>，存储在图数据库中。                       |
| RAG         | RAG是检索增强生成（Retrieval-augmented Generation）的缩写，是一种结合了大型语言模型的生成能力和检索系统的精确性的技术，用于提高生成内容的准确性、相关性和时效性。                                                                                                    |
| 倒排索引      | 倒排索引（Inverted Index）是一种数据结构，用于加速文本检索过程。它将文档中的词汇映射到出现该词汇的文档列表，从而实现根据词汇快速检索相关文档的目的。                                                  |
| 文本嵌入      | 文本嵌入是将文本信息映射到高维向量空间的过程，使得具有语义相似性的文本在向量空间中距离较近。                                                  |
| 文本相似度    | 文本相似度是衡量两段文本之间语义接近程度的度量。通过计算文本在嵌入空间中的相似性，可以评估它们在语义上的相似程度。                                                          |
| 排序与重排序   | 在信息检索中，排序指的是将检索到的文档按照其与查询的相关性进行排序。重排序则是在排序后的结果基础上再次调整文档的顺序，以进一步提高与用户查询的匹配度。                                                  |