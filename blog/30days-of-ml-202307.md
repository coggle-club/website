<!-- Coggle 30 Days of ML（23年7月） -->
<!-- 30天入门数据竞赛 -->
<!-- 2023-06-01 -->
<!-- <a target="_blank" href="https://www.zhihu.com/people/ashui233/">阿水</a>, <a target="_blank" href="https://www.zhihu.com/people/wang-he-13-93">鱼遇雨欲语与余</a>-->
<!-- <a href="https://coggle.club/blog/30days-of-ml-202306">学习资料</a>##<a href="https://shimo.im/forms/7GVxPfAGLeolSWmr/fill">打卡链接</a>-->

## Part1 内容介绍

近年来，人工智能在自然语言处理领域取得了巨大的进展，其中一项引人注目的技术是生成模型，如OpenAI的GPT-3.5。这类模型通过学习大量的文本数据，具备了生成高质量文本的能力，引发了一系列关于文本生成真实性的讨论。

本月学习内容包括：

- TFIDF文本分类器
- LSTM分类分类器
- BERT文本分类器



## Part2 活动安排


* 免费学习活动，不会收取任何费用。
* **请各位同学添加下面微信，并回复【竞赛学习】，即可参与。**

![](https://cdn.coggle.club/coggle666_qrcode.png)


## Part3 积分说明和奖励

为了激励各位同学完成的学习任务，将学习任务根据难度进行划分，并根据是否完成进行评分难度高中低的任务分别分数为3、2和1。在完成学习后（本次活动，截止8月8），将按照积分顺序进行评选 Top3 的学习者。

打卡地址：[https://shimo.im/forms/BGH249688Ac8EdIf/fill](https://shimo.im/forms/BGH249688Ac8EdIf/fill)

### 讯飞比赛奖励

> 前十名将获得由 “讯飞 x Datawhale” 联合颁发的优秀选手证书。

赛题在讯飞比赛平台上举办，可以在平台上提交结果并获取奖励。赛题设立一、二、三等奖及优秀奖共十名，具体详情如下：

- 一等奖：1支队伍，周赛一等奖证书，奖金：1000元；
- 二等奖：1支队伍，周赛二等奖证书，奖金：800元；
- 三等奖：1支队伍，周赛三等奖证书，奖金：500元；
- 优秀奖：10支队伍。



### 打卡积分奖励

此外在讯飞比赛的基础上，参赛选手可以参与打卡并获取如下奖励：

Top1的学习者将获得以下奖励：

- 蓝牙黑胶音箱
- Coggle 竞赛专访机会

Top2-3的学习者将获得以下奖励：
- 20元红包
- Coggle 竞赛专访机会



历史活动打卡链接，可以参考如下格式：
- [https://blog.csdn.net/weixin_42551154/article/details/125474519](https://blog.csdn.net/weixin_42551154/article/details/125474519)
- [https://blog.csdn.net/weixin_42551154/article/details/125481695](https://blog.csdn.net/weixin_42551154/article/details/125481695)


## Part4 ChatGPT检测器

### 背景介绍

近年来人工智能在自然语言处理领域取得了巨大的进展。其中一项引人注目的技术是生成模型，如OpenAI的GPT-3.5。这类模型通过学习大量的文本数据，具备了生成高质量文本的能力，从而引发了一系列关于文本生成真实性的讨论。


正因为生成模型的迅猛发展，也引发了一个新的挑战，即如何区分人类编写的文本与机器生成的文本。传统上，我们借助语法错误、逻辑不连贯等特征来辨别机器生成的文本，但随着生成模型的不断改进，这些特征变得越来越难以区分。因此，为了解决这一问题，研究人员开始探索使用NLP文本分类技术来区分人类编写的文本和机器生成的文本。

### 打卡任务
| 任务名称                                        | 所需技能             |
| ----------------------------------------------- | -------------------- |
| 报名比赛，下载比赛数据集并完成读取              | Pandas               |
| 对数据集字符进行可视化，统计标签和字符分布      | Pandas               |
| 使用 TFIDF 提取文本特征                         | Sklearn              |
| 使用 TFIDF 特征 和 线性模型完成训练和预测       | Sklearn              |
| 使用 TFIDF 特征 和 XGBoost 完成训练和预测       | Sklearn、XGBoost     |
| 学会训练 FastText、Word2Vec 词向量              | FastText、gensim     |
| 使用 Word2Vec 词向量，搭建 TextCNN 模型训练预测 | Pytorch、Keras       |
| 使用 Word2Vec 词向量，搭建 BILSTM 模型训练预测  | Pytorch、Keras       |
| 学会 Bert 基础，transformer 库基础使用          | Pytorch、transformer |
| 使用 Bert 在比赛数据集中完成预训练              | Pytorch、transformer |
| 使用 Bert 在比赛数据集上完成微调                | Pytorch、transformer |


#### 任务一：报名比赛，下载比赛数据集并完成读取
- 说明：在这个任务中，你需要访问比赛地址并完成比赛报名。然后，下载比赛数据集，并使用Pandas库完成数据集的读取和加载。
- 实践步骤：
  1. 访问比赛地址：[https://challenge.xfyun.cn/topic/info?type=text-detector&ch=vWxQGFU](https://challenge.xfyun.cn/topic/info?type=text-detector&ch=vWxQGFU)。
  2. 完成比赛报名并获取数据集下载链接。
  3. 使用下载链接下载比赛数据集。
  4. 使用Pandas库读取和加载数据集，将数据转化为可供处理的数据结构。

#### 任务二：对数据集字符进行可视化，统计标签和字符分布
- 说明：在这个任务中，你需要使用Pandas库对数据集的字符进行可视化，并统计数据集中的标签和字符的分布情况，以便更好地理解数据集。
- 实践步骤：
  1. 使用Pandas库读取和加载数据集。
  2. 使用Pandas的可视化功能，如柱状图或饼图，对数据集的字符进行可视化展示。
  3. 使用Pandas的统计功能，如value_counts()方法，统计数据集中的标签和字符的分布情况。

#### 任务三：使用TFIDF提取文本特征
- 说明：在这个任务中，你需要使用Sklearn库中的TFIDF技术来提取文本特征，将文本转化为可供机器学习算法使用的数值表示。
- 实践步骤：
  1. 准备文本数据集。
  2. 使用Sklearn的TfidfVectorizer类，设置相应的参数（如ngram_range、max_features等）来构建TFIDF特征提取器。
  3. 使用TfidfVectorizer的fit_transform()方法，对文本数据集进行特征提取，得到TFIDF特征矩阵。

#### 任务四：使用TFIDF特征和线性模型完成训练和预测
- 说明：在这个任务中，你需要使用TFIDF特征和线性模型（如逻辑回归）完成训练和预测，通过机器学习算法来区分人类编写的文本和机器生成的文本。
- 实践步骤：
  1. 准备TFIDF特征矩阵和相应的标签。
  2. 划分训练集和测试集。
  3. 使用Sklearn中的线性模型（如逻辑回归）进行训练，并使用训练好的模型对测试集进行预测。
  4. 评估模型的性能，如准确率、精确率、召回率等指标。

#### 任务五：使用TFIDF特征和XGBoost完成训练和预测
- 说明：在这个任务中，你需要使用TFIDF特征和XGBoost算法完成训练和预测，进一步提升文本分类的性能。
- 实践步骤：
  1. 准备TFIDF特征矩阵和相应的标签。
  2. 划分训练集和测试集。
  3. 使用Sklearn中的XGBoost算法进行训练，并使用训练好的模型对测试集进行预测。
  4. 评估模型的性能，如准确率、精确率、召回率等指标。

#### 任务六：学会训练FastText、Word2Vec词向量
- 说明：在这个任务中，你将学习如何训练FastText和Word2Vec词向量模型，这些词向量模型可以捕捉文本中的语义信息。
- 实践步骤：
  1. 准备大规模文本语料库。
  2. 使用FastText或gensim库中的Word2Vec类，设置相应的参数（如词向量维度、窗口大小、训练迭代次数等）来构建词向量模型。
  3. 使用Word2Vec类的build_vocab()方法，构建词汇表。
  4. 使用Word2Vec类的train()方法，训练词向量模型。

#### 任务七：使用Word2Vec词向量，搭建TextCNN模型进行训练和预测
- 说明：在这个任务中，你将使用Word2Vec词向量，搭建TextCNN模型进行文本分类的训练和预测，通过卷积神经网络来进行文本分类。
- 实践步骤：
  1. 准备Word2Vec词向量模型和相应的训练数据集。
  2. 构建TextCNN模型，包括卷积层、池化层、全连接层等。
  3. 将Word2Vec词向量应用到模型中，作为词特征的输入。
  4. 使用训练数据集对TextCNN模型进行训练。
  5. 使用训练好的TextCNN模型对测试数据集进行预测。

#### 任务八：使用Word2Vec词向量，搭建BILSTM模型进行训练和预测
- 说明：在这个任务中，你将使用Word2Vec词向量，搭建BILSTM模型进行文本分类的训练和预测，通过双向长短期记忆网络来进行文本分类。
- 实践步骤：
  1. 准备Word2Vec词向量模型和相应的训练数据集。
  2. 构建BILSTM模型，包括嵌入层、BILSTM层、全连接层等。
  3. 将Word2Vec词向量应用到模型中，作为词特征的输入。
  4. 使用训练数据集对BILSTM模型进行训练。
  5. 使用训练好的BILSTM模型对测试数据集进行预测。

#### 任务九：学会Bert基础，transformer库基础使用
- 说明：在这个任务中，你将学习Bert模型的基础知识，并了解transformer库的基本使用方法，transformer库提供了Bert模型的实现。
- 实践步骤：
  1. 学习Bert模型的原理和架构。
  2. 了解transformer库的基本使用方法，包括Bert模型的初始化、输入编码和特征提取等操作。

#### 任务十：使用Bert在比赛数据集中完成预训练
- 说明：在这个任务中，你将使用Bert模型在比赛数据集上完成预训练，通过预训练的Bert模型来提取文本特征。
- 实践步骤：
  1. 准备比赛数据集和相应的预训练参数。
  2. 使用transformer库中的Bert模型，加载预训练参数。
  3. 使用Bert模型对比赛数据集进行预训练，提取文本特征。

#### 任务十一：使用Bert在比赛数据集上完成微调
- 说明：在这个任务中，你将使用Bert模型在比赛数据集上进行微调，进一步提升文本分类的性能。
- 实践步骤：
  1. 准备比赛数据集和相应的微调参数。
  2. 使用transformer库中的Bert模型，加载微调参数。
  3. 使用微调后的Bert模型对比赛数据集进行微调，提高文本分类的性能。

通过完成这些任务，你将学习到丰富的文本分类技术和模型训练方法，掌握了使用Pandas、Sklearn、FastText、Word2Vec、Pytorch等工具和库进行文本处理和训练的技能。祝你在学习和实践中取得好成绩！
