<!-- Coggle 30 Days of ML（22年1&2月） -->
<!-- Coggle 30 Days of ML（22年1&2月） -->
<!-- 2022-1-1 -->
<!-- <a target="_blank" href="https://www.zhihu.com/people/finlayliu">阿水</a>, <a target="_blank" href="https://www.zhihu.com/people/wang-he-13-93">鱼遇雨欲语与余</a>-->
<!--  -->

## Part1 内容介绍

在给大家分享知识的过程中，发现很多同学在学习竞赛都存在较多的问题：

* 不知道如何使用LightGBM
* 不知道如何入手NLP比赛
* 不知道如何搭建模型
而上述问题都是一个竞赛选手、一个算法工程师所必备的。因此我们将从本月组织一次竞赛训练营活动，希望能够帮助大家入门数据竞赛。在活动中我们将布置具体竞赛任务，然后参与的同学们不断闯关完成，竟可能的帮助大家入门。


---


## Part2 活动安排

* 活动是免费学习活动，不会收取任何费用。
* **请各位同学添加下面微信，并回复【竞赛学习】，即可参与。**



---
# Part3 积分说明和奖励

为了激励各位同学完成的学习任务，将学习任务根据难度进行划分，并根据是否完成进行评分难度高中低的任务分别分数为 3、2 和 1。在完成 1-2月学习后，将按照积分顺序进行评选 Top3 的学习者。

**积分有问题可以联系小助手哦！**

**打卡可以写在一个地址，每次有新完成的可以重复提交打卡！**

Top1的学习者将获得以下**奖励**：

* Coggle 竞赛专访机会
* 《机器学习算法竞赛实战》，鱼佬签名版
Top2-3的学习者将获得以下**奖励**：

* Coggle 周边福利
* Coggle 竞赛专访机会
**使用PaddlePaddle完成学习的Top3同学，还可以领取百度提供的小礼物。**

注：

* Coggle 数据科学保留活动期间和结束后修改奖励和规则的权利。
* 如果有违反竞赛规则的情况，Coggle 数据科学保留取消相关参赛者的参与排名的权利。

---


## Part4 LightGBM实战

### 学习内容

LightGBM（Light Gradient Boosting Machine） 是微软开源的一个实现 GBDT 算法的框架，支持高效率的并行训练。LightGBM 提出的主要原因是为了解决 GBDT 在海量数据遇到的问题。本次学习内容包括使用LightGBM完成各种操作，包括竞赛和数据挖掘中的模型训练、验证和调参过程。

### 打卡汇总

|任务名称|难度|所需技能|
|:----|:----|:----|
|任务1：模型训练与预测|低|LightGBM|
|任务2：模型保存与加载|低|LightGBM|
|任务3：分类、回归和排序任务|中|LightGBM|
|任务4：模型可视化|低|LightGBM|
|任务5：模型调参（网格、随机、贝叶斯）|中|模型调参|
|任务6：模型微调与参数衰减|中|LightGBM|
|任务7：特征筛选方法|高|特征筛选方法|
|任务8：自定义损失函数|中|损失函数&评价函数|
|任务9：模型部署与加速|高|Treelite|

### 学习资料

[https://github.com/Microsoft/LightGBM](https://github.com/Microsoft/LightGBM)

### 打卡要求

**注：**

* **需要所有的任务可以写在一个Notebook内**
* **推荐在打卡过程中加入思考过程，可以加入尝试&资料记录**
* **打卡Notebook必须在百度 AI Studio平台运行，并设置公开**

---


## Part5 中文文本相似度

### 赛题介绍

[https://aistudio.baidu.com/aistudio/competition/detail/45/0/task-definition](https://aistudio.baidu.com/aistudio/competition/detail/45/0/task-definition)

### 赛题背景

千言是全面的面向自然语言理解和生成任务的中文开源数据集合，目前，千言项目已经针对8个任务，汇集了来自11所高校和企业的23个开源数据集，旨在为研究人员带来一站式的数据集浏览、整理、下载和评测的科研体验，共同推动中文信息处理技术的进步。

### 赛题任务

文本相似度旨在识别两段文本在语义上是否相似。文本相似度在自然语言处理领域是一个重要研究方向，同时在信息检索、新闻推荐、智能客服等领域都发挥重要作用，具有很高的商业价值。

目前学术界的一些公开中文文本相似度数据集，在相关论文的支撑下对现有的公开文本相似度模型进行了较全面的评估，具有较高权威性。

因此，本开源项目收集了这些权威的数据集，期望对模型效果进行综合的评价，旨在为研究人员和开发者提供学术和技术交流的平台，进一步提升文本相似度的研究水平，推动文本相似度在自然语言处理领域的应用和发展。

本次评测的文本相似度数据集包括公开的三个文本相似度数据集，分别为哈尔滨工业大学（深圳）的 LCQMC 和 BQ Coupus，以及谷歌的 PAWS-X（中文）。各数据集的简介如下：

* LCQMC
LCQMC（A Large-scale Chinese Question Matching Corpus）, 百度知道领域的中文问题匹配数据集，目的是为了解决在中文领域大规模问题匹配数据集的缺失。该数据集从百度知道不同领域的用户问题中抽取构建数据。

* BQ Corpus
BQ Corpus（Bank Question Corpus）, 银行金融领域的问题匹配数据，包括了从一年的线上银行系统日志里抽取的问题pair对，是目前最大的银行领域问题匹配数据。

* PAWS-X (中文)
PAWS (Paraphrase Adversaries from Word Scrambling)，谷歌发布的包含 7 种语言释义对的数据集，包括PAWS（英语） 与 PAWS-X（多语）。数据集里包含了释义对和非释义对，即识别一对句子是否具有相同的释义（含义），特点是具有高度重叠词汇，对于进一步提升模型对于强负例的判断很有帮助。

各个数据集的任务均一致，即判断两段文本在语义上是否相似的二分类任务：

|类型|句子1|句子2|标签（label）|
|:----|:----|:----|:----|
|相似文本|看图猜一电影名|看图猜电影|1|
|不相似文本|无线路由器怎么无线上网|无线上网卡和无线路由器怎么用|0|

### 打卡汇总

|任务名称|难度|所需技能|
|:----|:----|:----|
|任务1：报名比赛，下载比赛数据集并完成读取|低、1|Pandas|
|任务2：对句子对提取TFIDF以及统计特征，训练和预测|中、2|TDIDF|
|任务3：加载中文词向量，自己训练中文词向量|中、2|    |
|任务4：使用中文词向量完成mean/max/sif句子编码|高、3|    |
|    |    |    |
|任务5：搭建SiamCNN/LSTM模型，训练和预测|高、3|SiamCNN/SiamLSTM|
|任务6：搭建InferSent模型，训练和预测|高、3|InferSent|
|任务7：搭建ESIM模型，训练和预测|高、3|ESIM|
|    |    |    |
|任务8：使用BERT或ERNIE完成NSP任务|高、3|BERT|
|任务9：Bert-flow、Bert-white、SimCSE|高、3|SimCSE|

### 打卡要求

**注：**

* **需要所有的任务可以写在一个Notebook内**
* **推荐在打卡过程中加入思考过程，可以加入尝试&资料记录**
* **若使用Paddle进行打卡必须在百度 AI Studio平台运行，并设置公开**


---


## Part6 提问&回答

问：具体的活动是怎么安排的？

>有任务，自己先尝试。活动结束后会公开优秀打卡链接。
问：本次活动是收费的吗，最终奖品如何发放？

>活动是免费的，最终奖品按照积分排行Top3进行发放，如果排名有并列都发送奖励。
问：环境和配置是什么？

>在AI Studio上进行学习，python3和PaddlePaddle环境
问：AI Studio有什么学习资料？

>项目环境介绍：[https://ai.baidu.com/ai-doc/AISTUDIO/Dk3e2vxg9](https://ai.baidu.com/ai-doc/AISTUDIO/Dk3e2vxg9)
>Notebook环境：[https://ai.baidu.com/ai-doc/AISTUDIO/sk3e2z8sb](https://ai.baidu.com/ai-doc/AISTUDIO/sk3e2z8sb)

